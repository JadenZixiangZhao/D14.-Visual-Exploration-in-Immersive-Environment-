{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0nNAfGoi_Rr"
   },
   "source": [
    "# Final Poject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8Uf8wqy4YZr"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PnFhHCgtAUB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import random\n",
    "import sys\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv3D, UpSampling3D, MaxPool3D, Concatenate, Input, Add, Subtract,ZeroPadding3D, BatchNormalization,ZeroPadding2D,UpSampling2D,Reshape,Conv2D\n",
    "import pandas as pd\n",
    "import skimage as sk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as torchF\n",
    "from scipy import ndarray\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import progressbar\n",
    "import gc\n",
    "import pickle\n",
    "import math\n",
    "# !pip install visualkeras\n",
    "# import visualkeras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1DKXqfmjEqd"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBq1IvP2UBFT"
   },
   "outputs": [],
   "source": [
    "## Josh Loading Code\n",
    "# Just for RAM reasons, we are only going to look at the first coil. This will reduce the dimensionality without \n",
    "# meaningfully reducing the information. \n",
    "\n",
    "\n",
    "def loadKspace(input_Folder, batch_size, batch_index):\n",
    "  #Batch_size is the number of samples per training batch. \n",
    "  #Batch_Index is so that we can increment the batch number \n",
    "\n",
    "  #Create the paths to read the Input and Ground Truth Folders\n",
    "  inputPath = input_Folder + \"/Input/\"\n",
    "  GTPath  = input_Folder + \"/GT/\"\n",
    "\n",
    "  #We have to make sure each input file has a corresponding GT file. Therefore we're going to load in all files name and compare them.\n",
    "  inputNames = []\n",
    "  GTNames = []\n",
    "\n",
    "  for file in sorted(os.listdir(inputPath)):\n",
    "    inputNames.append(file)\n",
    "  for file in sorted(os.listdir(GTPath)):\n",
    "    GTNames.append(file)\n",
    "\n",
    "  #ValidInpute is a list of all the file names that appear in both the input and GT set. Must be ordered so that the batch code works correctly\n",
    "  validInputs = set(inputNames).intersection(set(GTNames))\n",
    "  validInputs = sorted(validInputs)\n",
    "  print(str(len(validInputs)) + \" Valid Sets\")\n",
    "\n",
    "  #Load in the inputs and GT. It's very inportant they load in the same order. Also create a progress bar\n",
    "  widgets = [\n",
    "           progressbar.Bar(),' (',\n",
    "           progressbar.Percentage(), ') ',\n",
    "          ]\n",
    "  bar = progressbar.ProgressBar(max_value= batch_size, widgets=widgets).start()\n",
    "\n",
    "  InputNps = []\n",
    "  GTNps = []\n",
    "  for i,fileName in enumerate(validInputs):\n",
    "    if(i<batch_size*batch_index or i>=batch_size*(batch_index+1)):\n",
    "      #ignore any samples outside of the current batch\n",
    "      continue\n",
    "    tempInput = np.load(inputPath+fileName) \n",
    "    tempGT = np.load(GTPath+fileName) \n",
    "    InputNps.append(tempInput)\n",
    "    GTNps.append(tempGT)\n",
    "    bar.update(i-batch_index*batch_size)\n",
    "  \n",
    "  return InputNps, GTNps\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgNYghm4UA_s"
   },
   "outputs": [],
   "source": [
    "def createMagnitude(kspaceArray):\n",
    "  #From the KSpace Data we can create the magnitude data. Input is either inputs or GT\n",
    "  widgets = [\n",
    "           progressbar.Bar(),' (',\n",
    "           progressbar.Percentage(), ') ',\n",
    "          ]\n",
    "  bar = progressbar.ProgressBar(max_value= len(kspaceArray), widgets=widgets).start()\n",
    "  magArray = []\n",
    "  for i,file in enumerate(kspaceArray):\n",
    "    magnitude = np.fft.ifft2(file)\n",
    "    magArray.append(magnitude)\n",
    "    bar.update(i)\n",
    "  \n",
    "  return magArray\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EZ6qQVWUA6g"
   },
   "outputs": [],
   "source": [
    "#Combine the kspace and magnitude data.\n",
    "inputsAll = []\n",
    "GTAll = []\n",
    "\n",
    "\n",
    "inputs, GT = loadKspace(\"/content/drive/My Drive/DLBI/Kspace/Val\", batch_size = 25, batch_index = 0)\n",
    "inputsMag = createMagnitude(inputs)\n",
    "GTMag = createMagnitude(GT)\n",
    "\n",
    "while(len(inputs)>0):\n",
    "  inputsAll.append(np.stack([inputs[0],inputsMag[0]], axis=-1))\n",
    "  del inputs[0], inputsMag[0] #Remove the variables from the name space so that they can be garbage collected\n",
    "  \n",
    "  GTAll.append(np.stack([GT[0],GTMag[0]], axis=-1))\n",
    "  del GT[0], GTMag[0] #Remove the variables from the name space so that they can be garbage collected\n",
    "\n",
    "  gc.collect() #Garbage Collection to free RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qq7933ZqNLHh"
   },
   "outputs": [],
   "source": [
    "print(len(inputsAll))\n",
    "print(inputsAll[0].shape)\n",
    "print(len(GTAll))\n",
    "print(GTAll[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8Wk-JkTD-ju"
   },
   "source": [
    "## Preprocessing of Data\n",
    "The current shape of the data is (n, 4, 18, 201, 402, 2). First are going to seprate the slices and add them to the batch number. Shape is now: (n\\*201, 4, 18, 402, 2). Next we are going to rotate the dimensions to (n\\*201, 2, 4, 402, 18). Then we are going to upsample to create better numbers for the convolution, creating (n\\*201, 2, 4, 448, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cVtlgbIqzCa"
   },
   "outputs": [],
   "source": [
    "def preprocessing(rawInput):\n",
    "\n",
    "  finalInput = []\n",
    "\n",
    "  while(len(rawInput)>0):\n",
    "    #rotate array from (4, 18, 201, 402, 2) to (201, 2, 4, 402, 18)\n",
    "    rawInputRotate = np.rot90(rawInput[0],1,(0,2))       #((201, 18, 4, 402, 2))\n",
    "    rawInputRotate = np.rot90(rawInputRotate,1,(1,4))    #((201, 2, 4, 402, 18))\n",
    "    # print(\"Rotated: Shape went from: \" + str(rawInput[0].shape) + \" to \" + str(rawInputRotate.shape))\n",
    "    del rawInput[0]\n",
    "    gc.collect()\n",
    "\n",
    "    #Histogram norm step [ADD HERE IF YOU THINK WE NEED IT]\n",
    "\n",
    "    #Pad last two axis to make convolution easier\n",
    "    padWidthOne = int((448 - rawInputRotate.shape[-2])/2)\n",
    "    padTwo = int((32 - rawInputRotate.shape[-1])/2)\n",
    "    rawInputPadded = np.pad(rawInputRotate, ((0,0),(0,0),(0,0),(padWidthOne,padWidthOne),(padTwo,padTwo)), 'constant')\n",
    "    # print(\"Padded: Shape went from: \" + str(rawInputRotate.shape) + \" to \" + str(rawInputPadded.shape))\n",
    "    del rawInputRotate\n",
    "    gc.collect()\n",
    "    \n",
    "    for i in range(201):\n",
    "      finalInput.append(rawInputPadded[i])\n",
    "    del rawInputPadded\n",
    "    gc.collect()\n",
    "    print(len(finalInput))\n",
    "    \n",
    "  finalInputNp = np.array([xi for xi in finalInput])\n",
    "  del finalInput\n",
    "  gc.collect()\n",
    "  return finalInputNp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPzV6NiFEiEm"
   },
   "outputs": [],
   "source": [
    "processedInputsAll = preprocessing(inputsAll)\n",
    "processedGTAll = preprocessing(GTAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lrRZvKDqzEu"
   },
   "outputs": [],
   "source": [
    "# ## Pickle Processed file \n",
    "processedDataTrain = [processedInputsAll, processedGTAll]\n",
    "# with open('/content/drive/My Drive/DLBI/Kspace/processedData25_0Train.pickle', 'wb') as handle:\n",
    "#   pickle.dump(processedDataTrain, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH7EiXLyiMqn"
   },
   "outputs": [],
   "source": [
    "processedDataVal = [processedInputsAll, processedGTAll]\n",
    "# with open('/content/drive/My Drive/DLBI/Kspace/processedData25_0Val.pickle', 'wb') as handle:\n",
    "#   pickle.dump(processedDataVal, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFheVk-dqzGy"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/DLBI/Kspace/processedData25_0Train.pickle', 'rb') as handle:\n",
    "    processedDataTrain = pickle.load(handle)\n",
    "with open('/content/drive/My Drive/DLBI/Kspace/processedData25_0Val.pickle', 'rb') as handle:\n",
    "    processedDataVal = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8QHUPp-m5nI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ssp1Hu-qzJM"
   },
   "outputs": [],
   "source": [
    "finalInputs = processedDataTrain[0]\n",
    "finalGT = processedDataTrain[1]\n",
    "finalInputsVal = processedDataVal[0]\n",
    "finalGTVal = processedDataVal[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A91zX6FiNfGs"
   },
   "outputs": [],
   "source": [
    "print(finalInputs.shape)\n",
    "print(finalGT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oxU7LZMjQ0l"
   },
   "source": [
    "## Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwAJZ523waTH"
   },
   "outputs": [],
   "source": [
    "#Model 6\n",
    "def reduceDim(inputReal, inputImg):\n",
    "    downReal = Conv3D(1, (1, 1, 1), padding= \"same\", data_format=\"channels_first\")(inputReal)\n",
    "    downImg = Conv3D(1, (1, 1, 1), padding= \"same\", data_format=\"channels_first\")(inputImg)\n",
    "    downSampleReal = Subtract()([downReal,downImg])\n",
    "    downSampleImg = Add()([downReal,downImg])\n",
    "    downSampleReal = Reshape((downSampleReal.shape[2:]))(downSampleReal)\n",
    "    downSampleImg = Reshape((downSampleImg.shape[2:]))(downSampleImg)\n",
    "    \n",
    "    return downSampleReal,downSampleImg\n",
    "\n",
    "def finalDimExpan(inputReal,inputImg):\n",
    "\n",
    "    upRealOne = Conv2D(4, (1, 1), padding= \"same\", data_format=\"channels_first\")(inputReal)\n",
    "    upImgOne = Conv2D(4, (1, 1), padding= \"same\", data_format=\"channels_first\")(inputImg)\n",
    "    upSampleRealOne = Subtract()([upRealOne,upImgOne])\n",
    "    upSampleImgOne = Add()([upRealOne,upImgOne])\n",
    "\n",
    "    upReal = Reshape(target_shape=(1,upSampleRealOne.shape[1],upSampleRealOne.shape[2],upSampleRealOne.shape[3] ))(upSampleRealOne)\n",
    "    upImg = Reshape(target_shape=(1,upSampleImgOne.shape[1],upSampleImgOne.shape[2],upSampleImgOne.shape[3] ))(upSampleImgOne)\n",
    "\n",
    "\n",
    "    upReal = Conv3D(2, (1, 1, 1), padding= \"same\",  data_format=\"channels_first\")(upReal)\n",
    "    upImg = Conv3D(2, (1, 1, 1), padding= \"same\", data_format=\"channels_first\")(upImg)\n",
    "    upSampleReal = Subtract()([upReal,upImg])\n",
    "    upSampleImg = Add()([upReal,upImg])\n",
    "    \n",
    "    return upSampleReal,upSampleImg\n",
    "\n",
    "def downConvolution(inputReal,inputImg, filter):\n",
    "\n",
    "    #Convolutions\n",
    "    OneReal = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(inputReal)\n",
    "    OneImg = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(inputImg)\n",
    "    CVLayerOneReal = Subtract()([OneReal,OneImg])\n",
    "    CVLayerOneImg = Add()([OneReal,OneImg])\n",
    "    \n",
    "    TwoReal = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerOneReal)\n",
    "    TwoImg = Conv2D(filter, 3, padding= \"same\", activation = \"relu\", data_format=\"channels_first\")(CVLayerOneImg)\n",
    "    CVLayerTwoReal = Subtract()([TwoReal,TwoImg])\n",
    "    CVLayerTwoImg = Add()([TwoReal,TwoImg])\n",
    "\n",
    "    ThreeReal = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerTwoReal)\n",
    "    ThreeImg = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerTwoImg)\n",
    "    CVLayerThreeReal = Subtract()([ThreeReal,ThreeImg])\n",
    "    CVLayerThreeImg = Add()([ThreeReal,ThreeImg])\n",
    "\n",
    "    #Pooling\n",
    "    CVLayerTwoRealPad = ZeroPadding2D((1,1), data_format=\"channels_first\")(CVLayerThreeReal)\n",
    "    CVLayerTwoImgPad = ZeroPadding2D((1,1), data_format=\"channels_first\")(CVLayerThreeImg)\n",
    "    poolOneReal = Conv2D(filter, 3, padding= \"valid\",strides = 2, data_format=\"channels_first\")(CVLayerTwoRealPad)\n",
    "    poolOneImg = Conv2D(filter, 3, padding= \"valid\",strides = 2, data_format=\"channels_first\")(CVLayerTwoImgPad)\n",
    "    poolReal = Subtract()([poolOneReal,poolOneImg])\n",
    "    poolImg = Add()([poolOneReal,poolOneImg])\n",
    "\n",
    "    poolReal = poolReal\n",
    "    poolImg = poolImg\n",
    "\n",
    "\n",
    "    return poolReal,poolImg, CVLayerThreeReal, CVLayerThreeImg\n",
    "\n",
    "\n",
    "def upConvolution(inputReal,inputImg, carryReal,carryImg, filter):\n",
    "\n",
    "    combinationReal = Concatenate(axis=0)([inputReal, carryReal])\n",
    "    combinationImg = Concatenate(axis=0)([inputImg, carryImg])\n",
    "\n",
    "    #Convolutions\n",
    "    OneReal = Conv2D(filter, 3, padding= \"same\",  data_format=\"channels_first\")(combinationReal)\n",
    "    OneImg = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(combinationImg)\n",
    "    CVLayerOneReal = Subtract()([OneReal,OneImg])\n",
    "    CVLayerOneImg = Add()([OneReal,OneImg])\n",
    "    \n",
    "    TwoReal = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerOneReal)\n",
    "    TwoImg = Conv2D(filter, 3, padding= \"same\",  data_format=\"channels_first\")(CVLayerOneImg)\n",
    "    CVLayerTwoReal = Subtract()([TwoReal,TwoImg])\n",
    "    CVLayerTwoImg = Add()([TwoReal,TwoImg])\n",
    "\n",
    "    ThreeReal = Conv2D(filter/2, 3, padding= \"same\",data_format=\"channels_first\")(CVLayerTwoReal)\n",
    "    ThreeImg = Conv2D(filter/2, 3, padding= \"same\",  data_format=\"channels_first\")(CVLayerTwoImg)\n",
    "    CVLayerThreeReal = Subtract()([ThreeReal,ThreeImg])\n",
    "    CVLayerThreeImg = Add()([ThreeReal,ThreeImg])\n",
    "    \n",
    "    \n",
    "    upsampleReal = UpSampling2D(size = (2,2), data_format=\"channels_first\")(CVLayerThreeReal)\n",
    "    upsampleImg = UpSampling2D(size = (2,2), data_format=\"channels_first\")(CVLayerThreeImg)\n",
    "\n",
    "    return upsampleReal,upsampleImg\n",
    "    \n",
    "def finalUpconv(inputReal,inputImg, carryReal,carryImg, filter):\n",
    "\n",
    "    combinationReal = Concatenate(axis=0)([inputReal, carryReal])\n",
    "    combinationImg = Concatenate(axis=0)([inputImg, carryImg])\n",
    "\n",
    "    OneReal = Conv2D(filter, 3, padding= \"same\",  data_format=\"channels_first\")(combinationReal)\n",
    "    OneImg = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(combinationImg)\n",
    "    CVLayerOneReal = Subtract()([OneReal,OneImg])\n",
    "    CVLayerOneImg = Add()([OneReal,OneImg])\n",
    "    \n",
    "    TwoReal = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerOneReal)\n",
    "    TwoImg = Conv2D(filter, 3, padding= \"same\",  data_format=\"channels_first\")(CVLayerOneImg)\n",
    "    CVLayerTwoReal = Subtract()([TwoReal,TwoImg])\n",
    "    CVLayerTwoImg = Add()([TwoReal,TwoImg])\n",
    "    \n",
    "    ThreeReal = Conv2D(filter, 1, padding= \"same\",  data_format=\"channels_first\")(CVLayerTwoReal)\n",
    "    ThreeImg = Conv2D(filter, 1, padding= \"same\",  data_format=\"channels_first\")(CVLayerTwoImg)\n",
    "    CVLayerThreeReal = Subtract()([ThreeReal,ThreeImg])\n",
    "    CVLayerThreeImg = Add()([ThreeReal,ThreeImg])\n",
    "\n",
    "    return CVLayerThreeReal, CVLayerThreeImg\n",
    "\n",
    "def bottomConv(inputReal,inputImg , filter):\n",
    "\n",
    "    OneReal = Conv2D(filter, 3, padding= \"same\",  data_format=\"channels_first\")(inputReal)\n",
    "    OneImg = Conv2D(filter, 3, padding= \"same\", data_format=\"channels_first\")(inputImg)\n",
    "    CVLayerOneReal = Subtract()([OneReal,OneImg])\n",
    "    CVLayerOneImg = Add()([OneReal,OneImg])\n",
    "    \n",
    "    TwoReal = Conv2D(filter/2, 3, padding= \"same\",  data_format=\"channels_first\")(CVLayerOneReal)\n",
    "    TwoImg = Conv2D(filter/2, 3, padding= \"same\", data_format=\"channels_first\")(CVLayerOneImg)\n",
    "    CVLayerTwoReal = Subtract()([TwoReal,TwoImg])\n",
    "    CVLayerTwoImg = Add()([TwoReal,TwoImg])\n",
    "\n",
    "    upsampleReal = UpSampling2D(size = (2,2), data_format=\"channels_first\")(CVLayerTwoReal)\n",
    "    upsampleImg = UpSampling2D(size = (2,2), data_format=\"channels_first\")(CVLayerTwoImg)\n",
    "\n",
    "    return upsampleReal, upsampleImg\n",
    "\n",
    "\n",
    "def make_model():\n",
    "\n",
    "    startingFilter = 128\n",
    "    input_layerReal = Input(shape= [2,4,448,32], name = \"Real\") \n",
    "    input_layerImg = Input(shape= [2,4,448,32], name = \"Img\") \n",
    "    print(\"Shape of input: \" + str(input_layerReal.shape))\n",
    "\n",
    "    ##Upsample the coil layer\n",
    "    firstUpSampleReal,firstUpSampleImg = reduceDim(input_layerReal,input_layerImg)\n",
    "    print(\"Shape of first upsample: \" + str(firstUpSampleReal.shape))\n",
    "\n",
    "    ## Down convolutions\n",
    "    downConvOneReal,downConvOneImg, carryOneReal,carryOneImg = downConvolution(firstUpSampleReal, firstUpSampleImg, startingFilter)\n",
    "    print(\"Shape of first down conv: \" + str(downConvOneReal.shape))\n",
    "    downConvTwoReal,downConvTwoImg, carryTwoReal,carryTwoImg = downConvolution(downConvOneReal, downConvOneImg, startingFilter*2)\n",
    "    print(\"Shape of second down conv: \" + str(downConvTwoReal.shape))\n",
    "    downConvThreeReal,downConvThreeImg, carryThreeReal,carryThreeImg = downConvolution(downConvTwoReal, downConvTwoImg, startingFilter*4)\n",
    "    print(\"Shape of three down conv: \" + str(downConvThreeReal.shape))\n",
    "    downConvFourReal,downConvFourImg, carryFourReal,carryFourImg = downConvolution(downConvThreeReal,downConvThreeImg, startingFilter*8)\n",
    "    print(\"Shape of four down conv: \" + str(downConvFourReal.shape))\n",
    "    finalConvReal,finalConvImg  = bottomConv( downConvFourReal,downConvFourImg, startingFilter*16)\n",
    "    print(\"Shape of final down conv: \" + str(finalConvReal.shape))\n",
    "\n",
    "    #Up Conv\n",
    "    upConvOneReal,upConvOneImg = upConvolution(finalConvReal,finalConvImg, carryFourReal,carryFourImg, startingFilter*8)\n",
    "    print(\"Shape of first up conv: \" + str(upConvOneReal.shape))\n",
    "    upConvTwoReal,upConvTwoImg = upConvolution(upConvOneReal,upConvOneImg, carryThreeReal,carryThreeImg, startingFilter*4)\n",
    "    print(\"Shape of second up conv: \" + str(upConvTwoReal.shape))\n",
    "    upConvThreeReal,upConvThreeImg = upConvolution(upConvTwoReal,upConvTwoImg, carryTwoReal,carryTwoImg, startingFilter*2)\n",
    "    print(\"Shape of third up conv: \" + str(upConvThreeReal.shape))\n",
    "    upConvFourReal,upConvFourImg = finalUpconv(upConvThreeReal,upConvThreeImg, carryOneReal,carryOneImg, startingFilter)\n",
    "    print(\"Shape of final up conv: \" + str(upConvFourReal.shape))\n",
    "\n",
    "    #Down sample coil layer\n",
    "    lastDownSampleReal,lastDownSampleImg  = finalDimExpan(upConvFourReal,upConvFourImg)\n",
    "    print(\"Final Shape: \" + str(lastDownSampleReal.shape))\n",
    "\n",
    "\n",
    "    return keras.models.Model(inputs=[input_layerReal,input_layerImg ], outputs=[lastDownSampleReal,lastDownSampleImg])\n",
    "\n",
    "def CustomLoss(yReal, yPred,):\n",
    "\n",
    "  lossReal = keras.losses.MeanAbsoluteError()(yReal[0],yPred[0] )\n",
    "\n",
    "  finalLoss = lossReal\n",
    "\n",
    "  return finalLoss\n",
    "\n",
    "model = make_model()\n",
    "opt = tf.keras.optimizers.Adam(0.000001)\n",
    "model.compile(loss = CustomLoss, optimizer=opt)\n",
    "model.save_weights(\"/content/drive/My Drive/DLBI/model4.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEbyfs-Ghx4P"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPS3grG4UGrA"
   },
   "outputs": [],
   "source": [
    "finalInputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNYuSmRNWcDP"
   },
   "outputs": [],
   "source": [
    "metaBatch = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qusdwr8NUGwJ"
   },
   "outputs": [],
   "source": [
    "while(gc.collect()>0):\n",
    "  continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CMv93DHxwaVm"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/DLBI/model4.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,  patience=50, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('/content/drive/My Drive/DLBI/best_model4.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "history = model.fit(\n",
    "    [finalInputs.real,finalInputs.imag],\n",
    "    [finalGT.real,finalGT.imag],\n",
    "    epochs=10000,\n",
    "    verbose = 1,\n",
    "    batch_size = 8,\n",
    "    validation_data = ([finalInputsVal.real,finalInputsVal.imag],[finalGTVal.real,finalGTVal.imag]),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4H5akN2pgC9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ci2Q2nO0waX7"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/DLBI/best_model4.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,  patience=50, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('/content/drive/My Drive/DLBI/best_model4B2.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "history2 = model.fit(\n",
    "    [finalInputs[metaBatch:metaBatch*2].real,finalInputs[metaBatch:metaBatch*2].imag],\n",
    "    [finalGT[metaBatch:metaBatch*2].real,finalGT[metaBatch:metaBatch*2].imag],\n",
    "    epochs=10000,\n",
    "    verbose = 1,\n",
    "    batch_size = 4,\n",
    "    validation_data = ([finalInputsVal[metaBatch:metaBatch*2].real,finalInputsVal[metaBatch:metaBatch*2].imag],[finalGTVal[metaBatch:metaBatch*2].real,finalGTVal[metaBatch:metaBatch*2].imag]),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D0g_RVtwaaK"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/DLBI/best_model4B2.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,  patience=50, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('/content/drive/My Drive/DLBI/best_model4B3.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "history3 = model.fit(\n",
    "    [finalInputs[metaBatch*2:metaBatch*3].real,finalInputs[metaBatch*2:metaBatch*3].imag],\n",
    "    [finalGT[metaBatch*2:metaBatch*3].real,finalGT[metaBatch*2:metaBatch*3].imag],\n",
    "    epochs=10000,\n",
    "    verbose = 1,\n",
    "    batch_size = 4,\n",
    "    validation_data = ([finalInputsVal[metaBatch*2:metaBatch*3].real,finalInputsVal[metaBatch*2:metaBatch*3].imag],[finalGTVal[metaBatch*2:metaBatch*3].real,finalGTVal[metaBatch*2:metaBatch*3].imag]),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN7OAwkCwace"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/DLBI/best_model4B3.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,  patience=50, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('/content/drive/My Drive/DLBI/best_model4B4.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "history4 = model.fit(\n",
    "    [finalInputs[metaBatch*3:metaBatch*4].real,finalInputs[metaBatch*3:metaBatch*4].imag],\n",
    "    [finalGT[metaBatch*3:metaBatch*4].real,finalGT[metaBatch*3:metaBatch*4].imag],\n",
    "    epochs=10000,\n",
    "    verbose = 1,\n",
    "    batch_size = 4,\n",
    "    validation_data = ([finalInputsVal[metaBatch*3:metaBatch*4].real,finalInputsVal[metaBatch*3:metaBatch*4].imag],[finalGTVal[metaBatch*3:metaBatch*4].real,finalGTVal[metaBatch*3:metaBatch*4].imag]),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td4j62A9wae4"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/DLBI/best_model4B4.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0,  patience=50, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('/content/drive/My Drive/DLBI/best_model4B5.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "history4 = model.fit(\n",
    "    [finalInputs[metaBatch*4:metaBatch*5].real,finalInputs[metaBatch*4:metaBatch*5].imag],\n",
    "    [finalGT[metaBatch*4:metaBatch*5].real,finalGT[metaBatch*4:metaBatch*5].imag],\n",
    "    epochs=10000,\n",
    "    verbose = 1,\n",
    "    batch_size = 4,\n",
    "    validation_data = ([finalInputsVal[metaBatch*4:metaBatch*5].real,finalInputsVal[metaBatch*4:metaBatch*5].imag],[finalGTVal[metaBatch*4:metaBatch*5].real,finalGTVal[metaBatch*4:metaBatch*5].imag]),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBGwqtH9xl-6"
   },
   "source": [
    "## Output of the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O0MW8LQxloi"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/content/drive/My Drive/DLBI/best_model4B4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2_TBRfJ_vq8"
   },
   "outputs": [],
   "source": [
    "while(gc.collect()>0):\n",
    "  continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9WCeOVtprGT"
   },
   "outputs": [],
   "source": [
    "metaBatch = 1000\n",
    "prediction = model.predict([finalInputs[:metaBatch].real,finalInputs[:metaBatch].imag], batch_size = 4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IehzAG3P3-6R"
   },
   "outputs": [],
   "source": [
    "GTForPrediction = [finalGT[:metaBatch].real, finalGT[:metaBatch].imag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybGe-w8yprIr"
   },
   "outputs": [],
   "source": [
    "# ## Pickle Processed file \n",
    "# with open('/content/drive/My Drive/DLBI/Kspace/prediction25_0B1.pickle', 'wb') as handle:\n",
    "#   pickle.dump(prediction, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-g9sRzAN5cal"
   },
   "outputs": [],
   "source": [
    "# ## Pickle Processed file \n",
    "# with open('/content/drive/My Drive/DLBI/Kspace/predGT25_0B1.pickle', 'wb') as handle:\n",
    "#   pickle.dump(GTForPrediction, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74guUHykprLB"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/DLBI/Kspace/prediction25_0B1.pickle', 'rb') as handle:\n",
    "    prediction = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMLuePd35bbU"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/DLBI/Kspace/predGT25_0B1.pickle', 'rb') as handle:\n",
    "    GTForPrediction = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAn4lQp25oXb"
   },
   "outputs": [],
   "source": [
    "print(prediction[0].shape)\n",
    "print(prediction[1].shape)\n",
    "print(GTForPrediction[0].shape)\n",
    "print(GTForPrediction[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EId3WDmL9XEp"
   },
   "outputs": [],
   "source": [
    "def reformImage(pred):\n",
    "  imgReal = pred[0]\n",
    "  imgImg = pred[1]\n",
    "\n",
    "  output = np.zeros((imgReal.shape),dtype=\"complex128\")\n",
    "  output = 1j*imgImg; output += imgReal\n",
    "\n",
    "  firstImage = output[:201, 0, 1, 23:425, 7:25]\n",
    "  plt.imshow(np.log(abs(firstImage[:,:,8])), cmap='gray');\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L48td6Fjn1g"
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_Jo5ovijnT6"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK_MQLDwaOWe"
   },
   "outputs": [],
   "source": [
    "# This belowing code is for real number setup\n",
    "\n",
    "batch_size = 32\n",
    "samples=990\n",
    "\n",
    "data=GTForPrediction[0]\n",
    "#data=prediction[0]\n",
    "data=data[0:samples]\n",
    "train_data=data        # The train data is ground truth data \n",
    "train_loader=torch.from_numpy(train_data)\n",
    "imgs = next(iter(train_loader))\n",
    "\n",
    "data2=prediction[0]\n",
    "#data2=GTForPrediction[0]\n",
    "data2=data2[0:samples]\n",
    "noise_data=data2      # Noise data means the output data from UNet or the predicted data from the Unet\n",
    "noise_loader=torch.from_numpy(noise_data) \n",
    "imgs2 = next(iter(noise_loader))\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b07G3v_kW26"
   },
   "outputs": [],
   "source": [
    "# This belowing code is for imagniary number setup\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data11=GTForPrediction[1]\n",
    "data11=data11[0:samples]\n",
    "train_data11=data11        # The train data is ground truth data \n",
    "train_loader11=torch.from_numpy(train_data11)\n",
    "imgs = next(iter(train_loader11))\n",
    "\n",
    "data22=prediction[1]\n",
    "data22=data22[0:samples]\n",
    "noise_data22=data22      # Noise data means the output data from UNet or the predicted data from the Unet\n",
    "noise_loader22=torch.from_numpy(noise_data22) \n",
    "imgs2 = next(iter(noise_loader22))\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvrVZQgUdBtV"
   },
   "outputs": [],
   "source": [
    "# Build the weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTv9Mih0PTo4"
   },
   "outputs": [],
   "source": [
    "# Create Generator\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Used to inherit the torch.nn Module\n",
    "        super(G, self).__init__()\n",
    "        # Meta Module - consists of different layers of Modules\n",
    "        self.main = nn.Sequential(\n",
    "                nn.Conv2d(4, 512, 3, stride=1, padding='same', bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                #nn.ReLU(True),\n",
    "                nn.Conv2d(512, 256, 3, stride=1, padding='same', bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                #nn.ReLU(True),\n",
    "                nn.Conv2d(256, 128, 3, stride=1, padding='same', bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                #nn.ReLU(True),\n",
    "                nn.Conv2d(128, 64, 3, stride=1, padding='same', bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                #nn.ReLU(True),\n",
    "                nn.Conv2d(64, 4, 3, stride=1, padding='same', bias=False),    # stride 4 to 20. 448 to 4.  64 back to 64\n",
    "                #nn.Tanh()\n",
    "                )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n",
    "\n",
    "# Creating the generator\n",
    "netG = G()\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LUmbrcmdPCr"
   },
   "outputs": [],
   "source": [
    "# Defining the discriminator\n",
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 2, stride=2, padding=1, bias=False),        # 16 back to 64\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(16, 128, 2, stride=2, padding=1, bias=False),      # 16 back to 64\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(128, 256, 2, stride=2, padding=1, bias=False),      \n",
    "                nn.BatchNorm2d(256),                                          \n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(256, 512, 2, stride=2, padding=1, bias=False),      # second 256 back to to 512\n",
    "                nn.BatchNorm2d(512),                                           # second 256 back to to 512\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(512, 1, 2, stride=4, padding=0, bias=False),    # second 1024 back to to 1 #strude 1 to 2.  8 to 1\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1)\n",
    "        #return output\n",
    "    \n",
    "    \n",
    "# Creating the discriminator\n",
    "netD = D()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cjbcf52udYsL"
   },
   "outputs": [],
   "source": [
    "# # To stored the final MRI images\n",
    "# !mkdir MRIresults\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNvPNVpTdhVg"
   },
   "outputs": [],
   "source": [
    "EPOCH = 3 # play with the parameters\n",
    "LR = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05GFTA0EbWtW"
   },
   "outputs": [],
   "source": [
    "# The belowing code is for real number training\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "for epoch in range(EPOCH):\n",
    "    for i,data1,data2 in zip(range(len(train_loader)),train_loader,noise_loader):\n",
    "      # 1st Step: Updating the weights of the neural network of the discriminator\n",
    "      netD.zero_grad()\n",
    "    \n",
    "      # Training the discriminator with a real image data of the dataset\n",
    "      real1 = data1.float()\n",
    "      input = Variable(real1)\n",
    "      #target = Variable(torch.ones(input.size()[0]))\n",
    "      #print(target.shape)\n",
    "      target = Variable(torch.ones(14)) # 28 back to 14\n",
    "      output = netD(input)\n",
    "      #print(\"this is for output\")\n",
    "      #print(output.shape)\n",
    "      errD_real = criterion(output, target)\n",
    "      errD_real.backward(retain_graph=True) \n",
    "\n",
    "      # Training the generator with a fake image data\n",
    "      data=data2.float()\n",
    "      noise = data       # Change back back \n",
    "      #print(\"this is for noise type\")\n",
    "      #print(type(noise))\n",
    "      #noise = Variable(torch.randn(input.size()[0], 4, 1, 1))    # cancel later\n",
    "      noise = Variable(noise)\n",
    "      #print(\"this is for noise shape\")\n",
    "      #print(noise.shape)\n",
    "\n",
    "      fake2 = netG(noise)\n",
    "      # print(\"fake 2 shape\")\n",
    "      # print(fake2.shape)\n",
    "      #target = Variable(torch.zeros(noise.size()[0]))\n",
    "      #print(target.shape)\n",
    "      target = Variable(torch.zeros(14))\n",
    "      output = netD(fake2.detach())\n",
    "      #print(output.shape)\n",
    "      errD_fake = criterion(output, target)\n",
    "      fake2 = netG(noise)\n",
    "\n",
    "      #target = Variable(torch.zeros(28672))\n",
    "      #output = netD(fake.detach())\n",
    "      #errD_fake = criterion(output, target)\n",
    "      #errD_fake.backward(retain_graph=True)\n",
    "        \n",
    "      # Backpropagating the total error\n",
    "      errD = errD_real + errD_fake\n",
    "      errD.backward()\n",
    "      optimizerD.step()\n",
    "        \n",
    "      # 2nd Step: Updating the weights of the neural network of the generator\n",
    "      netG.zero_grad()\n",
    "      #target = Variable(torch.ones(input.size()[0]))\n",
    "      target = Variable(torch.ones(14))\n",
    "      output = netD(fake2)\n",
    "      errG = criterion(output, target)\n",
    "      errG.backward()\n",
    "      optimizerG.step()\n",
    "        \n",
    "      # 3rd Step: Printing the losses \n",
    "      print('[%d/%d][%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch+1, EPOCH, i+1, len(noise_loader), errD.item(), errG.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-oEF9A7NCe4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0biMk_eyk2xs"
   },
   "outputs": [],
   "source": [
    "# The belowing code is for imaginary number training\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "for epoch in range(EPOCH):\n",
    "    for i,data1,data2 in zip(range(len(train_loader11)),train_loader11,noise_loader22):\n",
    "      # 1st Step: Updating the weights of the neural network of the discriminator\n",
    "      netD.zero_grad()\n",
    "    \n",
    "      # Training the discriminator with a real image of the dataset\n",
    "      real11 = data1.float()\n",
    "      input = Variable(real11)\n",
    "\n",
    "\n",
    "      #target = Variable(torch.ones(input.size()[0]))\n",
    "      target = Variable(torch.ones(14))\n",
    "      output = netD(input)\n",
    "      errD_real = criterion(output, target)\n",
    "      errD_real.backward(retain_graph=True) \n",
    "\n",
    "      # Training the generator with a fake image\n",
    "      data=data2.float()\n",
    "      noise = data\n",
    "      noise = Variable(noise)\n",
    "\n",
    "      fake = netG(noise)\n",
    "      target = Variable(torch.zeros(14))\n",
    "      output = netD(fake.detach())\n",
    "      errD_fake = criterion(output, target)\n",
    "      fake22 = netG(noise)\n",
    "\n",
    "\n",
    "\n",
    "      #target = Variable(torch.zeros(28672))\n",
    "      #output = netD(fake.detach())\n",
    "      #errD_fake = criterion(output, target)\n",
    "      #errD_fake.backward(retain_graph=True)\n",
    "        \n",
    "      # Backpropagating the total error\n",
    "      errD = errD_real + errD_fake\n",
    "      errD.backward()\n",
    "      optimizerD.step()\n",
    "        \n",
    "      # 2nd Step: Updating the weights of the neural network of the generator\n",
    "      netG.zero_grad()\n",
    "      #target = Variable(torch.ones(input.size()[0]))\n",
    "      target = Variable(torch.ones(14))\n",
    "      output = netD(fake22)\n",
    "      errG = criterion(output, target)\n",
    "      errG.backward()\n",
    "      optimizerG.step()\n",
    "        \n",
    "      # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n",
    "      print('[%d/%d][%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch, EPOCH, i+1, len(noise_loader), errD.item(), errG.item()))\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJQ2wetfNHwW"
   },
   "outputs": [],
   "source": [
    "print(fake22.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEVA0TT2NFu7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DLBIFinalProjectToSubmit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
